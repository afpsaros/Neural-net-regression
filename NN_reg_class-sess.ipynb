{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 2) (6, 2)\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "X_data = np.linspace(-1, 2, n)\n",
    "X_data = X_data.reshape((n, 1))\n",
    "# Y_data = X_data**2\n",
    "Y_data = np.cos(X_data / 5)**3 + 4* np.sin(2 * X_data)**3 + \\\n",
    ".3 * (X_data - 5)**2 + 0.02 * (X_data - 2)**3 \n",
    "\n",
    "Y_data += np.random.normal(0, 0.1, [n, 1])\n",
    "\n",
    "plt.plot(X_data, Y_data, 'bo')\n",
    "plt.show()\n",
    "\n",
    "data = np.concatenate((X_data, Y_data), axis=1)\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "data_tr, data_val= np.split(data, [int(0.8*n)], axis = 0)\n",
    "print(data_tr.shape, data_val.shape)\n",
    "n_tr, n_val = data_tr.shape[0], data_val.shape[0]\n",
    "\n",
    "n_eval = 300\n",
    "X_data = np.linspace(-1, 2, n_eval)\n",
    "X_data = X_data.reshape((n_eval, 1))\n",
    "# Y_data = X_data**2\n",
    "Y_data = np.cos(X_data / 5)**3 + 4* np.sin(2 * X_data)**3 + \\\n",
    ".3 * (X_data - 5)**2 + 0.02 * (X_data - 2)**3 \n",
    "\n",
    "# plt.plot(X_data, Y_data, 'bo')\n",
    "# plt.show()\n",
    "\n",
    "data_eval = np.concatenate((X_data, Y_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scores:\n",
    "    def errors(self):     \n",
    "        error = tf.reduce_mean(tf.square(self.fp - self.Y))\n",
    "        error_p = tf.math.abs(self.fp - self.Y)\n",
    "        return error, error_p\n",
    "                    \n",
    "    def pred(self, Xe):\n",
    "        return self.sess.run(self.fp, feed_dict={self.X: Xe})\n",
    "\n",
    "    def pred_w(self, Xe, W, b):\n",
    "        self.weights, self.biases = W, b\n",
    "        self.fp = self.ffn()\n",
    "        return self.sess.run(self.fp, feed_dict={self.X: Xe})\n",
    "    \n",
    "    def score(self, eval_dict):\n",
    "        Xe, Ye = list(eval_dict.values())\n",
    "        return self.sess.run(self.errors(), feed_dict = {self.X: Xe, self.Y: Ye})   \n",
    "    \n",
    "    def score_w(self, eval_dict, W, b):\n",
    "        Xe, Ye = list(eval_dict.values())\n",
    "        self.weights, self.biases = W, b\n",
    "        self.fp = self.ffn()\n",
    "        return self.sess.run(self.errors(), feed_dict = {self.X: Xe, self.Y: Ye})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class regressor(scores):\n",
    "    \n",
    "    def __init__(self, sess):\n",
    "        self.sess = sess\n",
    "        self.optimizer = tf.train.AdamOptimizer()\n",
    "        \n",
    "    def close_sess(self):\n",
    "        self.sess.close()\n",
    "    \n",
    "    def fit_from_dict(self, fit_dict):\n",
    "        return self.fit(*list(fit_dict.values()))  \n",
    "\n",
    "    def adv_fit_from_dict(self, fit_dict):\n",
    "        return self.adv_fit(*list(fit_dict.values()))     \n",
    "    \n",
    "    def fit(self, wd_par, num_epochs, Xt, Yt, lr = None):\n",
    "        \n",
    "        self.wd_par = wd_par\n",
    "        self.num_epochs = num_epochs\n",
    "        self.xmin = min(Xt)\n",
    "        self.xmax = max(Yt)\n",
    "        self.Xt = Xt\n",
    "        self.Yt = Yt    \n",
    "        self.lr = lr\n",
    "       \n",
    "        self.hyper_initial()\n",
    "        self.fp = self.ffn()\n",
    "        \n",
    "        self.error_mean = self.errors()[0]\n",
    "        \n",
    "        self.obj = self.error_mean + \\\n",
    "                        self.wd_par * tf.reduce_sum([tf.reduce_sum(tf.square(self.weights[i])) for i in self.weights])\n",
    "        \n",
    "        if self.lr is not None:\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate = self.lr)\n",
    "         \n",
    "        self.train_op = self.optimizer.minimize(self.obj)\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.sess.run(self.init)\n",
    "        \n",
    "        for epoch in range(self.num_epochs): \n",
    "            self.sess.run(self.train_op, feed_dict={self.X: self.Xt, self.Y: self.Yt}) \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def adv_fit(self, wd_par, num_epochs, Xt, Yt, Xv, Yv, lr = None):\n",
    "        \n",
    "        self.wd_par = wd_par   \n",
    "        self.num_epochs = num_epochs\n",
    "        self.xmin = min(Xt)\n",
    "        self.xmax = max(Yt)\n",
    "        self.Xt = Xt\n",
    "        self.Yt = Yt\n",
    "        self.Xv = Xv\n",
    "        self.Yv = Yv\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.hyper_initial()\n",
    "        self.fp = self.ffn()\n",
    "        \n",
    "        self.error_mean = self.errors()[0]\n",
    "        \n",
    "        self.obj = self.error_mean + \\\n",
    "                        self.wd_par * tf.reduce_sum([tf.reduce_sum(tf.square(self.weights[i])) for i in self.weights])\n",
    "                \n",
    "        if self.lr is not None:\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate = self.lr)\n",
    "            \n",
    "        self.train_op = self.optimizer.minimize(self.obj)\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.sess.run(self.init)\n",
    "        \n",
    "        self.check_w, self.check_b, self.tr_error, self.val_error = \\\n",
    "                    [[] for i in range(4)]   # not 4 * [[]] \n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.val_error.append(self.sess.run(self.error_mean, \\\n",
    "                  feed_dict={self.X: self.Xv, self.Y: self.Yv}))\n",
    "            check_w_, check_b_, tr_error_, _ = \\\n",
    "            self.sess.run([self.weights, self.biases, self.error_mean, self.train_op], \\\n",
    "                                                           feed_dict={self.X: self.Xt, self.Y: self.Yt})\n",
    "            \n",
    "            self.check_w.append(check_w_)\n",
    "            self.check_b.append(check_b_)\n",
    "            self.tr_error.append(tr_error_)\n",
    "\n",
    "        self.val_error.append(self.sess.run(self.error_mean, \\\n",
    "              feed_dict={self.X: self.Xv, self.Y: self.Yv}))\n",
    "        check_w_, check_b_, tr_error_ = \\\n",
    "            self.sess.run([self.weights, self.biases, self.error_mean], \\\n",
    "                                                       feed_dict={self.X: self.Xt, self.Y: self.Yt})        \n",
    "        self.check_w.append(check_w_)\n",
    "        self.check_b.append(check_b_)\n",
    "        self.tr_error.append(tr_error_)\n",
    "               \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(regressor):\n",
    "    def __init__(self, widths, sess):\n",
    "        \n",
    "        super().__init__(sess)\n",
    "        \n",
    "        self.widths = widths\n",
    "        self.layers = len(self.widths) - 2\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "        self.Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "        self.w_sizes = [[self.widths[i], self.widths[i + 1]] for i in range(len(self.widths) - 1)]\n",
    "        self.w_keys = [('').join(('h', str(i + 1))) for i in range(self.layers)] + ['out']\n",
    "        self.b_sizes = self.widths[1:]\n",
    "        self.b_keys = [('').join(('b', str(i + 1))) for i in range(self.layers)] + ['out']\n",
    "        \n",
    "    \n",
    "    def hyper_initial(self): \n",
    "        w_vars = []\n",
    "        for s in self.w_sizes:\n",
    "            std = np.sqrt(2 / (s[0] + s[1]))\n",
    "            w_vars.append(tf.Variable(tf.random_normal(s, stddev = std)))        \n",
    "        self.weights = dict(zip(self.w_keys, w_vars))\n",
    "\n",
    "        b_vars = [tf.Variable(tf.zeros([s])) for s in self.b_sizes]\n",
    "        self.biases = dict(zip(self.b_keys, b_vars))    \n",
    "\n",
    "    def ffn(self):\n",
    "        self.A = 2.0 * (self.X - self.xmin) / (self.xmax - self.xmin) - 1.0\n",
    "        layer = tf.tanh(tf.add(tf.matmul(self.A, self.weights['h1']), self.biases['b1']))    \n",
    "        for i in range(1, self.layers):\n",
    "            layer = tf.tanh(tf.add(tf.matmul(layer, self.weights[self.w_keys[i]]), self.biases[self.b_keys[i]]))        \n",
    "        layer = tf.add(tf.matmul(layer, self.weights['out']), self.biases['out'])\n",
    "        return layer\n",
    "    \n",
    "    @classmethod\n",
    "    def standard(cls, DNN_dict, sess):\n",
    "        n_in, n_out, layers, width = list(DNN_dict.values())\n",
    "        widths = [n_in] + layers * [width] + [n_out]\n",
    "        return cls(widths, sess)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# various parameters\n",
    "num_epochs = 500\n",
    "wd_par = 0\n",
    "lr = 1e-3\n",
    "\n",
    "Xt, Yt = data_tr[:, [0]], data_tr[:, [1]]\n",
    "Xv, Yv = data_val[:, [0]], data_val[:, [1]]\n",
    "Xe, Ye = data_eval[:, [0]], data_eval[:, [1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_dict = {\n",
    "    'input dimension': 1,\n",
    "    'output dimension': 1,\n",
    "    'number of layers': 4,\n",
    "    'layer width': 100, \n",
    "}\n",
    "\n",
    "fit_dict = {\n",
    "    'wd_par': wd_par,\n",
    "    'num_epochs': num_epochs,\n",
    "    'Xt': Xt,\n",
    "    'Yt': Yt,\n",
    "    'lr': lr\n",
    "}\n",
    "\n",
    "fit_dict = {\n",
    "    'wd_par': wd_par,\n",
    "    'num_epochs': num_epochs,\n",
    "    'Xt': Xt,\n",
    "    'Yt': Yt,\n",
    "    'Xv': Xv,\n",
    "    'Yv': Yv,\n",
    "    'lr': lr\n",
    "}\n",
    "\n",
    "eval_dict = {\n",
    "    'Xe': Xe,\n",
    "    'Ye': Ye\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22398233\n",
      "0.23664981\n",
      "0.2189327\n",
      "0.25223306\n",
      "0.22406593\n",
      "0.23402199\n",
      "0.20843334\n",
      "0.21111293\n",
      "0.2523642\n",
      "0.24309972\n",
      "2.6048466\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "with tf.Session() as sess:\n",
    "    n = 10\n",
    "    tic = time.perf_counter()\n",
    "    for k in range(n):\n",
    "    #     model = DNN.standard(DNN_dict).fit_from_dict(fit_dict)\n",
    "        model = DNN.standard(DNN_dict, sess).fit_from_dict(fit_dict)\n",
    "#         print(model.sess)\n",
    "        print(model.score(eval_dict)[0])\n",
    "    toc = time.perf_counter()\n",
    "    print((toc-tic)/n)\n",
    "\n",
    "# model.close_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sess = tf.Session()\n",
    "# sess.run(init)\n",
    "# tr_error = [sess.run(error, feed_dict={X: data_tr[:, [0]], Y: data_tr[:, [1]]})]\n",
    "# val_error = [sess.run(error, feed_dict={X: data_val[:, [0]], Y: data_val[:, [1]]})]\n",
    "# check_w = [sess.run(weights)]\n",
    "# check_b = [sess.run(biases)]\n",
    "\n",
    "# tic = time.perf_counter()\n",
    "# for epoch in range(num_epochs):\n",
    "#     tr_error_, weights_, biases_, _ = \\\n",
    "#     sess.run([error, weights, biases, train_op], feed_dict={X: data_tr[:, [0]], Y: data_tr[:, [1]]})\n",
    "#     check_w.append(weights_)\n",
    "#     check_b.append(biases_)\n",
    "#     tr_error.append(tr_error_)\n",
    "#     val_error.append(sess.run(error, feed_dict={X: data_val[:, [0]], Y: data_val[:, [1]]}))       \n",
    "        \n",
    "# toc = time.perf_counter()\n",
    "# print(toc-tic)\n",
    "# # print('Optimization finished with validation RMSE {:.6f}'.format(np.sqrt(val_error[-1])))\n",
    "# # print('{:03d} epochs run'.format(epoch + 1))\n",
    "# # print('best parameters at epoch {:03d}'.format(best + 1))\n",
    "\n",
    "# plt.title('Training vs validation error', fontsize = 20)\n",
    "# plt.yscale('log')\n",
    "# # plt.axvline(x = best, label = 'selected epoch', color = 'r')\n",
    "# plt.plot(tr_error, label = 'training')\n",
    "# plt.plot(val_error, label = 'validation')\n",
    "# plt.xlabel('Epoch', fontsize = 15)\n",
    "# plt.ylabel('Error', fontsize = 15)\n",
    "# plt.legend(bbox_to_anchor=(1.4, 1.0))\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_1 = model.pred_w(Xe, ws[0], bs[0])\n",
    "# pred_2 = model.pred_w(Xe, ws[1], bs[1])\n",
    "# plt.title('Predictions', fontsize = 20)\n",
    "# plt.axvline(x = -1, label = 'data bounds', color = 'r')\n",
    "# plt.axvline(x = 2, color = 'r')\n",
    "# plt.plot(Xe, pred_1, label = '1')\n",
    "# plt.plot(Xe, pred_2, label = '2')\n",
    "# plt.plot(data_eval[:, [0]], data_eval[:, [1]], label = 'true function')\n",
    "# plt.xlabel('x', fontsize = 15)\n",
    "# plt.ylabel('y', fontsize = 15)\n",
    "# plt.legend(bbox_to_anchor=(1.4, 1.0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "a = defaultdict(float)\n",
    "\n",
    "vals = [1, 2, 3]\n",
    "\n",
    "a = dict(zip(['a', 'b', 'c'], vals))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v():\n",
    "    return 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-60d63656a472>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-60d63656a472>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    Recurse(, 4)\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def Recurse(y, number):\n",
    "    if number > 1:\n",
    "        for x in range (y):\n",
    "            print(x)\n",
    "        Recurse( y, number - 1 )\n",
    "        \n",
    "Recurse(, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0], [1, 1], [0, 2]]\n"
     ]
    }
   ],
   "source": [
    "def partition(n, d, depth=0):\n",
    "    if d == depth:\n",
    "        return [[]]\n",
    "    return [\n",
    "        item + [i]\n",
    "        for i in range(n+1)\n",
    "        for item in partition(n-i, d, depth=depth+1)\n",
    "        ]\n",
    "\n",
    "\n",
    "# extend with n-sum(entries)\n",
    "n = 2\n",
    "d = 2\n",
    "lst = [[n-sum(p)] + p for p in partition(n, d-1)]\n",
    "\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0., 0.],\n",
      "        [1., 1.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [1., 1.]]]), array([[[5., 5.],\n",
      "        [5., 5.]],\n",
      "\n",
      "       [[6., 6.],\n",
      "        [6., 6.]]]), array([[[18., 20.],\n",
      "        [18., 20.]],\n",
      "\n",
      "       [[18., 20.],\n",
      "        [18., 20.]]])]\n",
      "[[ 0  5 18]\n",
      " [ 1  5 18]\n",
      " [ 0  6 18]\n",
      " [ 1  6 18]\n",
      " [ 0  5 19]\n",
      " [ 1  5 19]\n",
      " [ 0  6 19]\n",
      " [ 1  6 19]]\n"
     ]
    }
   ],
   "source": [
    "ev_params = {'a': np.linspace(0, 1, 2), 'b': np.linspace(5, 6, 2), 'c': np.linspace(18, 20, 2)}\n",
    "\n",
    "grid = np.meshgrid(np.linspace(0, 1, 2), np.linspace(5, 6, 2), np.linspace(18, 20, 2))\n",
    "print(grid)\n",
    "\n",
    "grid = np.mgrid[0:2,5:7,18:20].T.reshape(-1, 3)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# a = a.T.reshape(-1, 3)\n",
    "\n",
    "print(a)\n",
    "\n",
    "emp = {'a': None, 'b': None, 'c': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['a', 'b', 'c']\n",
    "\n",
    "# z = [aa for aa in a]\n",
    "\n",
    "# for zz in z:\n",
    "    \n",
    "#     for j, key in enumerate(keys):\n",
    "#         emp[key] = zz[j]\n",
    "        \n",
    "#     print(emp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 1., 1., 0., 0., 1., 1.]), array([5., 5., 5., 5., 6., 6., 6., 6.]), array([18., 20., 18., 20., 18., 20., 18., 20.])]\n",
      "(0.0, 5.0, 18.0)\n"
     ]
    }
   ],
   "source": [
    "ev_params = {'a': np.linspace(0, 1, 2), 'b': np.linspace(5, 6, 2), 'c': np.linspace(18, 20, 2)}\n",
    "\n",
    "grid = np.meshgrid(*list(ev_params.values()))\n",
    "n = grid[0].size\n",
    "\n",
    "grid_d = dict(zip(keys, [g.reshape(n) for g in grid]))\n",
    "\n",
    "# print([g.reshape(n) for g in grid])\n",
    "for i in range(n):\n",
    "    for key in keys:\n",
    "        emp[key] = grid_d[key][i]\n",
    "\n",
    "    \n",
    "    \n",
    "# print()\n",
    "# print(grid[0].reshape(n))\n",
    "# print(grid[0].reshape(8, 1))\n",
    "# a = np.squeeze(grid[0].reshape(-1, n))\n",
    "# print(d)\n",
    "# print([el for el in np.squeeze(d['a'])])\n",
    "\n",
    "# for i in range(n):\n",
    "#     for j, key in enumerate(keys):\n",
    "#         print(grid[j])\n",
    "# #         emp[key] = grid[j][i]\n",
    "        \n",
    "# #     print(emp)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# for zz in grid:\n",
    "    \n",
    "#     for j, key in enumerate(keys):\n",
    "#         emp[key] = zz[j]\n",
    "        \n",
    "#     print(emp)\n",
    "\n",
    "vals = [g.reshape(n) for g in grid]\n",
    "\n",
    "print(vals)\n",
    "a = list(zip(*vals))\n",
    "print(a[0])\n",
    "# print(vals[:][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
